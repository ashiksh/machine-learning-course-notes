{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"### Data Cleaning\n-----\nMost of the dataset are not cleaned and usually have messy data so we must clean the data before use that. \n\nData cleaning involves dealing with\n\n* Missing data\n* Duplicated data\n* Outliers in the data\n* Extra data that might not be needed\n* Inconsistent data\n* Converting data into a standard format so that it is easy to work on"},{"metadata":{},"cell_type":"markdown","source":"### Missing Value\n----\nDuring data collection and entry it is possible that some values are missed or data was not available. \nPandas writes `NaN(Not a number)` when it found a missing value. It does not include NaN in any calculation like sum, mean etc. \n\nwe can detect missing value by using `isnull` function. whenever it found a missing value, return `True` otherwisde `False`. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/california-housing-prices/housing.csv')\n\nprint('missing value in every column :', df.isnull().sum())\nprint('total missing value of all the columns : ', df.isnull().sum().sum())\n\n#show all the rows of missing value \ndisplay(df[df['total_bedrooms'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filtering missing values\n-------\nwhen encounter missing value we can either remove those values or fill with suitable value"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('shape of original dataframe : ', df.shape)\n\n# remove missing rows \nnew_df = df.dropna()\nprint('shape of filtered dataframe :', new_df.shape)\n\n# remove the whole column (bad idea)\nnew_df = df.dropna(axis=1)\nprint('shape of filtered dataframe : ', new_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filling numerical missing values\n----\nRemoving missing missing value is bad idea, the best way to deal with missing value is filling those missing value with suitable value. The strategy behind filling missing values can vary from problem to problem. In some cases, filling in with the **mean** or **median** value works very well, while in some cases **interpolation** works better. Interpolation is a mathematical technique of constructing new points from a range of points."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total missing values : \",df.isnull().sum().sum())\n\n#fill value with median value \nvalue = df['total_bedrooms'].median()\nnew_df = df['total_bedrooms'].fillna(value)\n\n#fill missing value with interpolation \nnew_df = df.interpolate('linear')\n\nprint(\"Total missing values : \",new_df.isnull().sum().sum())\n\n#print(new_df.loc[290, 'total_bedrooms'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For non-numerical missing values, we can simply write **missing** because we cannot use mathematical methods like mean, median, or interpolation to estimate these."},{"metadata":{},"cell_type":"markdown","source":"### Duplicates Data\n----\nwe may have some duplicate data that we need remove. \nwe can use `dataframe.duplicated(subset=list of column names)` to find duplicate data and `drop_duplicates(subset=list of columns names)` to drop duplicate data from dataframe."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}